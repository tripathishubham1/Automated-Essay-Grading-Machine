{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EGM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXlD2cjDS1DZtqfYzoRsaw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tripathishubham1/Automated-Essay-Grading-Machine/blob/main/EGM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO4SxIzOj5xe"
      },
      "source": [
        "#**Automated Essay Grading Machine**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtX15DlAkKhU"
      },
      "source": [
        "## Importing Modules & Dataset Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xfKkejeNZKF"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "df_train = pd.read_csv('/content/train.csv')\n",
        "df_test = pd.read_csv('/content/test.csv')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQZJreA0l2d0"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "dhCT7oIGPMwF",
        "outputId": "7fa088ac-e87b-4483-f346-9131f8fbd547"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>promptId</th>\n",
              "      <th>uniqueId</th>\n",
              "      <th>essay</th>\n",
              "      <th>evaluator_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1_323</td>\n",
              "      <td>At present age, our education system is not go...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1_238</td>\n",
              "      <td>I am agree the tightly defined curriculum of o...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1_212</td>\n",
              "      <td>I strongly agree with the statement that tight...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1_117</td>\n",
              "      <td>Our education system is nice quitely but i dis...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1_229</td>\n",
              "      <td>i am totally agree with the statement that tig...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>1235</td>\n",
              "      <td>5</td>\n",
              "      <td>5_419</td>\n",
              "      <td>The entire world is in the race of producing a...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1236</th>\n",
              "      <td>1236</td>\n",
              "      <td>5</td>\n",
              "      <td>5_420</td>\n",
              "      <td>The race in the development of weapons are pro...</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1237</th>\n",
              "      <td>1237</td>\n",
              "      <td>5</td>\n",
              "      <td>5_421</td>\n",
              "      <td>In an era where every second person hopes and ...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>1238</td>\n",
              "      <td>5</td>\n",
              "      <td>5_422</td>\n",
              "      <td>INTRODUCTION :Since the beginning of the time ...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>1239</td>\n",
              "      <td>5</td>\n",
              "      <td>5_423</td>\n",
              "      <td>\"To conquer a nation, first disarm its citizen...</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1240 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...  evaluator_rating\n",
              "0              0  ...               3.0\n",
              "1              1  ...               4.0\n",
              "2              2  ...               2.0\n",
              "3              3  ...               2.0\n",
              "4              4  ...               3.0\n",
              "...          ...  ...               ...\n",
              "1235        1235  ...               3.0\n",
              "1236        1236  ...               2.5\n",
              "1237        1237  ...               4.0\n",
              "1238        1238  ...               3.0\n",
              "1239        1239  ...               4.5\n",
              "\n",
              "[1240 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L079uOOkd-w"
      },
      "source": [
        "##Preprocesing Of Text Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn0I2yu7kdcS",
        "outputId": "1850caea-9323-4fb9-fa61-95029dde2b4a"
      },
      "source": [
        "train_score = df_train['evaluator_rating']\n",
        "train_e = df_train['essay'].tolist()\n",
        "test_e = df_test['essay'].tolist()\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')\n",
        "train_sents=[]\n",
        "test_sents=[]\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def fun1(x):\n",
        "  x = re.sub(\"[^A-Za-z]\",\" \",x)\n",
        "  x.lower()\n",
        "  fil_sen = []\n",
        "  words = x.split()\n",
        "  for w in words:\n",
        "    if w not in stop_words:\n",
        "      fil_sen.append(w)\n",
        "  return fil_sen\n",
        "\n",
        "def fun2(essay):\n",
        "  essay = essay.strip()\n",
        "  tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "  raw = tokenizer.tokenize(essay)\n",
        "  final_words = []\n",
        "  for i in raw:\n",
        "    if len(i)>0:\n",
        "      final_words.append(fun1(i))\n",
        "  return final_words\n",
        "\n",
        "for i in train_e:\n",
        "  train_sents+=fun2(i)\n",
        "for i in test_e:\n",
        "  test_sents+=fun2(i)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyxibvSMk2xL"
      },
      "source": [
        "##Vectorization & Applying LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPNOsSF9l56h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15e40e1-ec15-443d-b821-f3889e7002e1"
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "num_features = 300 \n",
        "min_word_count = 40\n",
        "num_workers = 4\n",
        "context = 10\n",
        "downsampling = 1e-3\n",
        "\n",
        "model = Word2Vec(train_sents, \n",
        "                 workers=num_workers, \n",
        "                 size=num_features, \n",
        "                 min_count = min_word_count, \n",
        "                 window = context, \n",
        "                 sample = downsampling)\n",
        "\n",
        "model.init_sims(replace=True)\n",
        "model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
        "\n",
        "def makeVec(words, model, num_features):\n",
        "    vec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    noOfWords = 0.\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "    for i in words:\n",
        "        if i in index2word_set:\n",
        "            noOfWords += 1\n",
        "            vec = np.add(vec,model[i])        \n",
        "    vec = np.divide(vec,noOfWords)\n",
        "    return vec\n",
        "\n",
        "\n",
        "def getVecs(essays, model, num_features):\n",
        "    c=0\n",
        "    essay_vecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "    for i in essays:\n",
        "        essay_vecs[c] = makeVec(i, model, num_features)\n",
        "        c+=1\n",
        "    return essay_vecs\n",
        "\n",
        "\n",
        "clean_train=[]\n",
        "for i in train_e:\n",
        "    clean_train.append(fun1(i))\n",
        "training_vectors = getVecs(clean_train, model, num_features)\n",
        "\n",
        "clean_test=[] \n",
        "\n",
        "for i in test_e:\n",
        "    clean_test.append(fun1(i))\n",
        "testing_vectors = getVecs(clean_test, model, num_features)\n",
        "\n",
        "training_vectors = np.array(training_vectors)\n",
        "testing_vectors = np.array(testing_vectors)\n",
        "\n",
        "# Reshaping train and test vectors to 3 dimensions\n",
        "training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
        "testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
        "lstm_model = get_model()\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owg2M0jwlYep"
      },
      "source": [
        "##Fitting Model & Predicting the Output of Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBgkcr-8fcbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f897d5f3-65a8-4ba4-ea41-4b2836c6bc47"
      },
      "source": [
        "lstm_model.fit(training_vectors, train_score, batch_size=155, epochs=100,validation_split=0.5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 34s 867ms/step - loss: 7.6674 - mae: 2.5810 - val_loss: 6.1969 - val_mae: 2.3114\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 4.8519 - mae: 2.0346 - val_loss: 2.5241 - val_mae: 1.4765\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.7956 - mae: 1.1370 - val_loss: 1.2815 - val_mae: 0.9243\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 1.2400 - mae: 0.8587 - val_loss: 1.2251 - val_mae: 0.8685\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0439 - mae: 0.7953 - val_loss: 1.2275 - val_mae: 0.8720\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.1834 - mae: 0.8406 - val_loss: 1.2222 - val_mae: 0.8650\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.2202 - mae: 0.8455 - val_loss: 1.2067 - val_mae: 0.8369\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.1183 - mae: 0.7900 - val_loss: 1.2692 - val_mae: 0.9133\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.1581 - mae: 0.8322 - val_loss: 1.2150 - val_mae: 0.8394\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.1038 - mae: 0.7957 - val_loss: 1.2320 - val_mae: 0.8581\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.1358 - mae: 0.8122 - val_loss: 1.2364 - val_mae: 0.7912\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.1433 - mae: 0.8070 - val_loss: 1.2376 - val_mae: 0.8456\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.1376 - mae: 0.8075 - val_loss: 1.3283 - val_mae: 0.9450\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0719 - mae: 0.7896 - val_loss: 1.2604 - val_mae: 0.8560\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.1226 - mae: 0.8213 - val_loss: 1.2590 - val_mae: 0.8398\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0058 - mae: 0.7674 - val_loss: 1.2783 - val_mae: 0.8738\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0987 - mae: 0.8107 - val_loss: 1.3028 - val_mae: 0.8072\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0490 - mae: 0.7767 - val_loss: 1.2910 - val_mae: 0.8308\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.1138 - mae: 0.8072 - val_loss: 1.2962 - val_mae: 0.8690\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.1238 - mae: 0.7948 - val_loss: 1.3051 - val_mae: 0.8573\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0703 - mae: 0.7936 - val_loss: 1.3112 - val_mae: 0.8767\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0546 - mae: 0.7865 - val_loss: 1.3264 - val_mae: 0.8400\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9638 - mae: 0.7473 - val_loss: 1.3284 - val_mae: 0.8893\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.2004 - mae: 0.8375 - val_loss: 1.4857 - val_mae: 0.8292\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0732 - mae: 0.7735 - val_loss: 1.3366 - val_mae: 0.8564\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9993 - mae: 0.7557 - val_loss: 1.3998 - val_mae: 0.8324\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0039 - mae: 0.7413 - val_loss: 1.4296 - val_mae: 0.8338\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0859 - mae: 0.7936 - val_loss: 1.3523 - val_mae: 0.8721\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0185 - mae: 0.7831 - val_loss: 1.3611 - val_mae: 0.8743\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0200 - mae: 0.7675 - val_loss: 1.3665 - val_mae: 0.8986\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 1.0689 - mae: 0.7769 - val_loss: 1.4076 - val_mae: 0.8617\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0851 - mae: 0.7947 - val_loss: 1.4385 - val_mae: 0.8543\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9776 - mae: 0.7393 - val_loss: 1.4049 - val_mae: 0.8676\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.9146 - mae: 0.7091 - val_loss: 1.3921 - val_mae: 0.9030\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0145 - mae: 0.7797 - val_loss: 1.4591 - val_mae: 0.8650\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0527 - mae: 0.7623 - val_loss: 1.5130 - val_mae: 0.8663\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0382 - mae: 0.7730 - val_loss: 1.4465 - val_mae: 0.8747\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0315 - mae: 0.7701 - val_loss: 1.5321 - val_mae: 0.8730\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0809 - mae: 0.7847 - val_loss: 1.4192 - val_mae: 0.9066\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0298 - mae: 0.7813 - val_loss: 1.4900 - val_mae: 0.8759\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.0810 - mae: 0.7855 - val_loss: 1.4846 - val_mae: 0.8737\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0640 - mae: 0.7639 - val_loss: 1.4245 - val_mae: 0.9135\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0845 - mae: 0.8010 - val_loss: 1.4421 - val_mae: 0.8863\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0259 - mae: 0.7776 - val_loss: 1.5072 - val_mae: 0.8772\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0034 - mae: 0.7583 - val_loss: 1.4716 - val_mae: 0.8812\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0147 - mae: 0.7769 - val_loss: 1.6439 - val_mae: 0.8851\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9705 - mae: 0.7343 - val_loss: 1.5007 - val_mae: 0.8817\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0858 - mae: 0.7844 - val_loss: 1.5457 - val_mae: 0.8794\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9838 - mae: 0.7500 - val_loss: 1.4426 - val_mae: 0.9140\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.0287 - mae: 0.7702 - val_loss: 1.5694 - val_mae: 0.8851\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9713 - mae: 0.7417 - val_loss: 1.5183 - val_mae: 0.8876\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 1.0025 - mae: 0.7648 - val_loss: 1.6852 - val_mae: 0.8968\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.0001 - mae: 0.7555 - val_loss: 1.6566 - val_mae: 0.8927\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.0001 - mae: 0.7414 - val_loss: 1.5372 - val_mae: 0.8915\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0976 - mae: 0.7822 - val_loss: 1.5167 - val_mae: 0.8950\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.0446 - mae: 0.7772 - val_loss: 1.4975 - val_mae: 0.8987\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0121 - mae: 0.7714 - val_loss: 1.4756 - val_mae: 0.9083\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0381 - mae: 0.7847 - val_loss: 1.5355 - val_mae: 0.8931\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9494 - mae: 0.7240 - val_loss: 1.5463 - val_mae: 0.8945\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9981 - mae: 0.7535 - val_loss: 1.6642 - val_mae: 0.8960\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.9664 - mae: 0.7467 - val_loss: 1.5090 - val_mae: 0.8934\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0364 - mae: 0.7737 - val_loss: 1.4790 - val_mae: 0.9031\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.1122 - mae: 0.8229 - val_loss: 1.5209 - val_mae: 0.8955\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.1107 - mae: 0.7821 - val_loss: 1.6095 - val_mae: 0.8943\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.9649 - mae: 0.7385 - val_loss: 1.6193 - val_mae: 0.8966\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0585 - mae: 0.7787 - val_loss: 1.6217 - val_mae: 0.8973\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0256 - mae: 0.7656 - val_loss: 1.6537 - val_mae: 0.9010\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.1270 - mae: 0.8049 - val_loss: 1.7213 - val_mae: 0.9067\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0503 - mae: 0.7840 - val_loss: 1.4976 - val_mae: 0.8999\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0628 - mae: 0.7761 - val_loss: 1.5995 - val_mae: 0.8949\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0337 - mae: 0.7706 - val_loss: 1.5325 - val_mae: 0.8949\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.9706 - mae: 0.7504 - val_loss: 1.7738 - val_mae: 0.9119\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0322 - mae: 0.7640 - val_loss: 1.6682 - val_mae: 0.8990\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.9927 - mae: 0.7474 - val_loss: 1.8703 - val_mae: 0.9326\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0992 - mae: 0.7957 - val_loss: 1.5796 - val_mae: 0.8976\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0756 - mae: 0.7863 - val_loss: 1.5243 - val_mae: 0.9000\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0731 - mae: 0.7988 - val_loss: 1.4992 - val_mae: 0.9062\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0335 - mae: 0.7691 - val_loss: 1.5216 - val_mae: 0.8979\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0362 - mae: 0.7703 - val_loss: 1.5500 - val_mae: 0.8979\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0212 - mae: 0.7479 - val_loss: 1.5418 - val_mae: 0.9033\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 1.0259 - mae: 0.7805 - val_loss: 1.6404 - val_mae: 0.8988\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 1.0566 - mae: 0.7779 - val_loss: 1.6365 - val_mae: 0.9015\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0295 - mae: 0.7587 - val_loss: 1.5805 - val_mae: 0.9074\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.0270 - mae: 0.7691 - val_loss: 1.5271 - val_mae: 0.9125\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0830 - mae: 0.7901 - val_loss: 1.5653 - val_mae: 0.9121\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0070 - mae: 0.7600 - val_loss: 1.5366 - val_mae: 0.9068\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.0296 - mae: 0.7754 - val_loss: 1.6641 - val_mae: 0.9064\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0265 - mae: 0.7694 - val_loss: 1.7078 - val_mae: 0.9110\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 1.0270 - mae: 0.7632 - val_loss: 1.6695 - val_mae: 0.9075\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.0964 - mae: 0.7905 - val_loss: 1.5878 - val_mae: 0.9079\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 1.1250 - mae: 0.8125 - val_loss: 1.8553 - val_mae: 0.9334\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.1189 - mae: 0.7890 - val_loss: 1.6782 - val_mae: 0.9063\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.1595 - mae: 0.8149 - val_loss: 1.6326 - val_mae: 0.9013\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.9489 - mae: 0.7352 - val_loss: 1.5844 - val_mae: 0.9012\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.9584 - mae: 0.7400 - val_loss: 1.5793 - val_mae: 0.9027\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0921 - mae: 0.7928 - val_loss: 1.5827 - val_mae: 0.8981\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0288 - mae: 0.7662 - val_loss: 1.7678 - val_mae: 0.9136\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.0755 - mae: 0.7643 - val_loss: 1.6146 - val_mae: 0.8985\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.0446 - mae: 0.7640 - val_loss: 1.6179 - val_mae: 0.9010\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.0474 - mae: 0.7644 - val_loss: 1.6769 - val_mae: 0.9044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7dc3f2b210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO7BqxKygkhB",
        "outputId": "86ded372-a785-4b03-b63c-dfc441beba57"
      },
      "source": [
        "lstm_model.save('final_lstm.h5')\n",
        "y_pred = lstm_model.predict(testing_vectors)\n",
        "y_pred = np.around(y_pred)\n",
        "y_pred"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [4.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [4.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [3.],\n",
              "       [4.],\n",
              "       [3.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa-l8P_amYNS"
      },
      "source": [
        "df_test['predicted_score'] = y_pred.tolist()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "kuGpYmFInFKA",
        "outputId": "b914353d-c591-45d6-df4b-dda020d3592a"
      },
      "source": [
        "df_test"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>promptId</th>\n",
              "      <th>uniqueId</th>\n",
              "      <th>essay</th>\n",
              "      <th>predicted_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1_315</td>\n",
              "      <td>Curriculum has been adopted in many schools. T...</td>\n",
              "      <td>[3.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1_214</td>\n",
              "      <td>I strongly agree with the statement ,  The tig...</td>\n",
              "      <td>[3.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1_196</td>\n",
              "      <td>Imagination and creativity is the most importa...</td>\n",
              "      <td>[3.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1_178</td>\n",
              "      <td>In our eduction system leaves no room for imag...</td>\n",
              "      <td>[3.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1_201</td>\n",
              "      <td>I will agree at some what extend, because if w...</td>\n",
              "      <td>[3.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>300</td>\n",
              "      <td>5</td>\n",
              "      <td>5_146</td>\n",
              "      <td>Earth is a creation of God and everything that...</td>\n",
              "      <td>[3.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>301</td>\n",
              "      <td>5</td>\n",
              "      <td>5_65</td>\n",
              "      <td>production of arms and weapons in this present...</td>\n",
              "      <td>[3.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>302</td>\n",
              "      <td>5</td>\n",
              "      <td>5_151</td>\n",
              "      <td>Race to become more powerful can destroy the e...</td>\n",
              "      <td>[3.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>303</td>\n",
              "      <td>5</td>\n",
              "      <td>5_404</td>\n",
              "      <td>In its attempt to harness the power of the ato...</td>\n",
              "      <td>[4.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>304</td>\n",
              "      <td>5</td>\n",
              "      <td>5_360</td>\n",
              "      <td>Racein the production of arms and weapons in t...</td>\n",
              "      <td>[3.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>305 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ...  predicted_score\n",
              "0             0  ...            [3.0]\n",
              "1             1  ...            [3.0]\n",
              "2             2  ...            [3.0]\n",
              "3             3  ...            [3.0]\n",
              "4             4  ...            [3.0]\n",
              "..          ...  ...              ...\n",
              "300         300  ...            [3.0]\n",
              "301         301  ...            [3.0]\n",
              "302         302  ...            [3.0]\n",
              "303         303  ...            [4.0]\n",
              "304         304  ...            [3.0]\n",
              "\n",
              "[305 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfzBy588nGx8"
      },
      "source": [
        "df_test.to_csv(r'/content/test_prediction.csv', index = False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0uZQ46sntlt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}